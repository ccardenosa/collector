diff --git a/bpf/filler_helpers.h b/bpf/filler_helpers.h
index e37cea8..4f29825 100644
--- a/bpf/filler_helpers.h
+++ b/bpf/filler_helpers.h
@@ -493,8 +493,11 @@ static __always_inline u16 bpf_pack_addr(struct filler_data *data,
 		res = bpf_probe_read_str(&data->buf[(data->state->tail_ctx.curoff + 1) & SCRATCH_SIZE_HALF],
 					 UNIX_PATH_MAX,
 					 usrsockaddr_un->sun_path);
-
-		size += res;
+		if (res == -EFAULT) {
+			size = 0;
+		} else {
+			size += res;
+		}
 
 		break;
 	default:
@@ -703,8 +706,11 @@ static __always_inline long bpf_fd_to_socktuple(struct filler_data *data,
 		int res = bpf_probe_read_str(&data->buf[(data->state->tail_ctx.curoff + 1 + 8 + 8) & SCRATCH_SIZE_HALF],
 					     UNIX_PATH_MAX,
 					     us_name);
-
-		size += res;
+		if (res == -EFAULT) {
+			size = 0;
+		} else {
+			size += res;
+		}
 
 		break;
 	}
@@ -745,7 +751,7 @@ static __always_inline int __bpf_val_to_ring(struct filler_data *data,
 			res = bpf_probe_read_str(&data->buf[data->state->tail_ctx.curoff & SCRATCH_SIZE_HALF],
 						 PPM_MAX_ARG_SIZE,
 						 (const void *)val);
-			if (res < 0)
+			if (res == -EFAULT)
 				return PPM_FAILURE_INVALID_USER_MEMORY;
 			len = res;
 		} else {
diff --git a/bpf/fillers.h b/bpf/fillers.h
index 2458b09..e2be0b2 100644
--- a/bpf/fillers.h
+++ b/bpf/fillers.h
@@ -617,6 +617,7 @@ static __always_inline unsigned long bpf_get_mm_swap(struct mm_struct *mm)
 
 FILLER(sys_brk_munmap_mmap_x, true)
 {
+#if 0
 	struct task_struct *task;
 	unsigned long total_vm = 0;
 	struct mm_struct *mm;
@@ -661,10 +662,14 @@ FILLER(sys_brk_munmap_mmap_x, true)
 	res = bpf_val_to_ring_type(data, swap, PT_UINT32);
 
 	return res;
+#else
+	return PPM_SKIP_EVENT;
+#endif
 }
 
 FILLER(sys_mmap_e, true)
 {
+#if 0
 	unsigned long val;
 	int res;
 
@@ -715,6 +720,9 @@ FILLER(sys_mmap_e, true)
 	res = bpf_val_to_ring(data, val);
 
 	return res;
+#else
+	return PPM_SKIP_EVENT;
+#endif
 }
 
 FILLER(sys_fcntl_e, true)
@@ -1451,7 +1459,8 @@ static __always_inline pid_t bpf_task_tgid_vnr(struct task_struct *task)
 	return bpf_pid_vnr(bpf_task_tgid(task));
 }
 
-#elif LINUX_VERSION_CODE < KERNEL_VERSION(4, 19, 0)
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(4, 19, 0) && \
+    ( !defined(RHEL_RELEASE_CODE) || RHEL_RELEASE_CODE < RHEL_RELEASE_VERSION(8,1) )
 
 static __always_inline pid_t bpf_task_pid_nr_ns(struct task_struct *task,
 						enum pid_type type,
@@ -1544,7 +1553,7 @@ static __always_inline int __bpf_append_cgroup(struct css_set *cgroups,
 	int res = bpf_probe_read_str(&buf[off & SCRATCH_SIZE_HALF],
 				     SCRATCH_SIZE_HALF,
 				     subsys_name);
-	if (res < 0)
+	if (res == -EFAULT)
 		return PPM_FAILURE_INVALID_USER_MEMORY;
 
 	off += res - 1;
@@ -1591,7 +1600,7 @@ static __always_inline int __bpf_append_cgroup(struct css_set *cgroups,
 		res = bpf_probe_read_str(&buf[off & SCRATCH_SIZE_HALF],
 						SCRATCH_SIZE_HALF,
 						cgroup_path[k]);
-		if (res < 0)
+		if (res == -EFAULT)
 			return PPM_FAILURE_INVALID_USER_MEMORY;
 
 		if (res > 1) {
@@ -1694,7 +1703,7 @@ static __always_inline int bpf_accumulate_argv_or_env(struct filler_data *data,
 			return PPM_FAILURE_BUFFER_FULL;
 
 		len = bpf_probe_read_str(&data->buf[off & SCRATCH_SIZE_HALF], SCRATCH_SIZE_HALF, arg);
-		if (len < 0)
+		if (len == -EFAULT)
 			return PPM_FAILURE_INVALID_USER_MEMORY;
 
 		*args_len += len;
@@ -1796,7 +1805,7 @@ FILLER(proc_startupdate, true)
 						SCRATCH_SIZE_HALF,
 						&data->buf[data->state->tail_ctx.curoff & SCRATCH_SIZE_HALF]);
 
-		if (exe_len < 0)
+		if (exe_len == -EFAULT)
 			return PPM_FAILURE_INVALID_USER_MEMORY;
 
 		/*
@@ -3515,6 +3524,7 @@ FILLER(sys_procexit_e, false)
 
 FILLER(sched_switch_e, false)
 {
+#if 0
 	struct sched_switch_args *ctx;
 	struct task_struct *task;
 	unsigned long total_vm;
@@ -3592,6 +3602,9 @@ FILLER(sched_switch_e, false)
 	res = bpf_val_to_ring_type(data, swap, PT_UINT32);
 
 	return res;
+#else
+	return PPM_SKIP_EVENT;
+#endif
 }
 
 FILLER(sys_pagefault_e, false)
@@ -3632,6 +3645,7 @@ FILLER(sys_pagefault_e, false)
 
 FILLER(sys_signaldeliver_e, false)
 {
+#if 0
 	struct signal_deliver_args *ctx;
 	pid_t spid = 0;
 	int sig;
@@ -3682,6 +3696,9 @@ FILLER(sys_signaldeliver_e, false)
 	res = bpf_val_to_ring(data, sig);
 
 	return res;
+#else
+	return PPM_SKIP_EVENT;
+#endif
 }
 
 FILLER(sys_quotactl_e, true)
diff --git a/bpf/probe.c b/bpf/probe.c
index a9f9729..279933d 100644
--- a/bpf/probe.c
+++ b/bpf/probe.c
@@ -34,6 +34,7 @@ int bpf_##event(struct type *ctx)
 
 BPF_PROBE("raw_syscalls/", sys_enter, sys_enter_args)
 {
+#if 0
 	const struct syscall_evt_pair *sc_evt;
 	struct sysdig_bpf_settings *settings;
 	enum ppm_event_type evt_type;
@@ -77,12 +78,14 @@ BPF_PROBE("raw_syscalls/", sys_enter, sys_enter_args)
 		return 0;
 
 	call_filler(ctx, &stack_ctx, evt_type, settings, drop_flags);
+#endif
 #endif
 	return 0;
 }
 
 BPF_PROBE("raw_syscalls/", sys_exit, sys_exit_args)
 {
+#if 0
 	const struct syscall_evt_pair *sc_evt;
 	struct sysdig_bpf_settings *settings;
 	enum ppm_event_type evt_type;
@@ -116,11 +119,13 @@ BPF_PROBE("raw_syscalls/", sys_exit, sys_exit_args)
 	}
 
 	call_filler(ctx, ctx, evt_type, settings, drop_flags);
+#endif
 	return 0;
 }
 
 BPF_PROBE("sched/", sched_process_exit, sched_process_exit_args)
 {
+#if 0
 	struct sysdig_bpf_settings *settings;
 	enum ppm_event_type evt_type;
 	struct task_struct *task;
@@ -142,11 +147,13 @@ BPF_PROBE("sched/", sched_process_exit, sched_process_exit_args)
 	evt_type = PPME_PROCEXIT_1_E;
 
 	call_filler(ctx, ctx, evt_type, settings, UF_NEVER_DROP);
+#endif
 	return 0;
 }
 
 BPF_PROBE("sched/", sched_switch, sched_switch_args)
 {
+#if 0
 	struct sysdig_bpf_settings *settings;
 	enum ppm_event_type evt_type;
 
@@ -160,6 +167,7 @@ BPF_PROBE("sched/", sched_switch, sched_switch_args)
 	evt_type = PPME_SCHEDSWITCH_6_E;
 
 	call_filler(ctx, ctx, evt_type, settings, 0);
+#endif
 	return 0;
 }
 
@@ -184,18 +192,29 @@ static __always_inline int bpf_page_fault(struct page_fault_args *ctx)
 	return 0;
 }
 
+#if 0
 BPF_PROBE("exceptions/", page_fault_user, page_fault_args)
 {
+#if 0
 	return bpf_page_fault(ctx);
+#else
+	return 0;
+#endif
 }
 
 BPF_PROBE("exceptions/", page_fault_kernel, page_fault_args)
 {
+#if 0
 	return bpf_page_fault(ctx);
+#else
+	return 0;
+#endif
 }
+#endif
 
 BPF_PROBE("signal/", signal_deliver, signal_deliver_args)
 {
+#if 0
 	struct sysdig_bpf_settings *settings;
 	enum ppm_event_type evt_type;
 
@@ -209,6 +228,7 @@ BPF_PROBE("signal/", signal_deliver, signal_deliver_args)
 	evt_type = PPME_SIGNALDELIVER_E;
 
 	call_filler(ctx, ctx, evt_type, settings, UF_ALWAYS_DROP);
+#endif
 	return 0;
 }
 
diff --git a/bpf/quirks.h b/bpf/quirks.h
index a26bfd9..410b0fe 100644
--- a/bpf/quirks.h
+++ b/bpf/quirks.h
@@ -40,6 +40,8 @@ or GPL2.txt for full copies of the license.
 #define BPF_SUPPORTS_RAW_TRACEPOINTS
 #endif
 
+#define RHEL_RELEASE_VERSION(X,Y) 0
+
 #endif /* RHEL_RELEASE_CODE */
 /* Redefine asm_volatile_goto to work around clang not supporting it
  */
diff --git a/ppm_cputime.c b/ppm_cputime.c
index 5e7c7e6..71563b0 100644
--- a/ppm_cputime.c
+++ b/ppm_cputime.c
@@ -231,7 +231,7 @@ static void cputime_advance(cputime_t *counter, cputime_t new)
  * runtime accounting.
  */
 static void cputime_adjust(struct task_cputime *curr,
-#if (LINUX_VERSION_CODE >= KERNEL_VERSION(4, 3, 0))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(4, 3, 0)) || (PPM_RHEL_RELEASE_CODE > 0 && PPM_RHEL_RELEASE_CODE >= PPM_RHEL_RELEASE_VERSION(7, 6))
 			   struct prev_cputime *prev,
 #else
 			   struct cputime *prev,
diff --git a/ppm_events.c b/ppm_events.c
index 6c321f6..7e498e3 100644
--- a/ppm_events.c
+++ b/ppm_events.c
@@ -24,7 +24,7 @@ or GPL2.txt for full copies of the license.
 #include <linux/version.h>
 #include <linux/module.h>
 #include <linux/kernel.h>
-#include <asm/mman.h>
+#include <linux/mman.h>
 #include <linux/in.h>
 #if LINUX_VERSION_CODE <= KERNEL_VERSION(2, 6, 20)
 #include <linux/mount.h>
